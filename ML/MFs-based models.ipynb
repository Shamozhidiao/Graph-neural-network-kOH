{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "319f947b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\shap\\utils\\_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\utils\\_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\utils\\_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\utils\\_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\utils\\_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\utils\\_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\utils\\_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\utils\\_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\utils\\_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\maskers\\_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\maskers\\_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\maskers\\_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "D:\\anaconda\\lib\\site-packages\\shap\\explainers\\_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import  XGBRegressor\n",
    "import shap\n",
    "\n",
    "import sys\n",
    "import rdkit\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from IPython.display import SVG\n",
    "from rdkit import rdBase\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import PyMol\n",
    "from rdkit.Chem.Draw import DrawMorganBit, DrawMorganBits,DrawMorganEnv, IPythonConsole\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from rdkit.Chem import PyMol\n",
    "from rdkit.Chem import MACCSkeys\n",
    "\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48df62b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ECFP_2', 'ECFP_5', 'ECFP_12', 'ECFP_14', 'ECFP_16', 'ECFP_34', 'ECFP_37', 'ECFP_42', 'ECFP_43', 'ECFP_54', 'ECFP_65', 'ECFP_72', 'ECFP_76', 'ECFP_81', 'ECFP_91', 'ECFP_104', 'ECFP_113', 'ECFP_115', 'ECFP_117', 'ECFP_118', 'ECFP_120', 'ECFP_122', 'ECFP_129', 'ECFP_131', 'ECFP_140', 'ECFP_141', 'ECFP_145', 'ECFP_148', 'ECFP_159', 'ECFP_166', 'ECFP_172', 'ECFP_176', 'ECFP_193', 'ECFP_203', 'ECFP_211', 'ECFP_215', 'ECFP_217', 'ECFP_223', 'ECFP_228', 'ECFP_232', 'ECFP_233', 'ECFP_234', 'ECFP_243', 'ECFP_251', 'ECFP_252', 'ECFP_256', 'ECFP_269', 'ECFP_280', 'ECFP_284', 'ECFP_286', 'ECFP_290', 'ECFP_295', 'ECFP_296', 'ECFP_300', 'ECFP_315', 'ECFP_318', 'ECFP_323', 'ECFP_334', 'ECFP_343', 'ECFP_351', 'ECFP_357', 'ECFP_358', 'ECFP_368', 'ECFP_379', 'ECFP_390', 'ECFP_393', 'ECFP_404', 'ECFP_408', 'ECFP_417', 'ECFP_427', 'ECFP_428', 'ECFP_429', 'ECFP_431', 'ECFP_433', 'ECFP_434', 'ECFP_453', 'ECFP_457', 'ECFP_464', 'ECFP_474', 'ECFP_483', 'ECFP_485', 'ECFP_486', 'ECFP_487', 'ECFP_490', 'ECFP_493', 'ECFP_512', 'ECFP_513', 'ECFP_541', 'ECFP_544', 'ECFP_562', 'ECFP_578', 'ECFP_579', 'ECFP_584', 'ECFP_592', 'ECFP_606', 'ECFP_611', 'ECFP_615', 'ECFP_651', 'ECFP_657', 'ECFP_660', 'ECFP_673', 'ECFP_676', 'ECFP_680', 'ECFP_688', 'ECFP_693', 'ECFP_695', 'ECFP_696', 'ECFP_699', 'ECFP_700', 'ECFP_714', 'ECFP_716', 'ECFP_719', 'ECFP_722', 'ECFP_723', 'ECFP_726', 'ECFP_727', 'ECFP_729', 'ECFP_740', 'ECFP_741', 'ECFP_746', 'ECFP_751', 'ECFP_754', 'ECFP_787', 'ECFP_791', 'ECFP_795', 'ECFP_796', 'ECFP_800', 'ECFP_807', 'ECFP_808', 'ECFP_815', 'ECFP_817', 'ECFP_821', 'ECFP_824', 'ECFP_826', 'ECFP_832', 'ECFP_839', 'ECFP_842', 'ECFP_843', 'ECFP_850', 'ECFP_862', 'ECFP_864', 'ECFP_870', 'ECFP_876', 'ECFP_882', 'ECFP_888', 'ECFP_889', 'ECFP_894', 'ECFP_898', 'ECFP_905', 'ECFP_914', 'ECFP_927', 'ECFP_933', 'ECFP_936', 'ECFP_940', 'ECFP_947', 'ECFP_954', 'ECFP_961', 'ECFP_968', 'ECFP_981', 'ECFP_982', 'ECFP_1005', 'ECFP_1018', 'ECFP_1020']\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "df_ = pd.read_csv('MORGAN-1024molecular_fingerprints.csv')\n",
    "for col in df_.columns:\n",
    "    if df_[col].var() <= 0.03:\n",
    "       # print(\"remove low variance column: {}\".format(col))\n",
    "        df_.drop(columns=col, inplace=True)\n",
    "        \n",
    "fileds_to_use = []\n",
    "for col in df_.columns:\n",
    "    fileds_to_use.append(col)\n",
    "\n",
    "print(fileds_to_use)\n",
    "print(len(fileds_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a29af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MF = pd.read_csv('1-MORGAN-1024molecular_fingerprints.csv')\n",
    "df_val = pd.read_csv('2-MORGAN-1024molecular_fingerprints.csv')\n",
    "df_test = pd.read_csv('3-MORGAN-1024molecular_fingerprints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb2ee111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集特征: (1033, 163)\n",
      "训练集标签: (1033,)\n",
      "验证集特征: (129, 163)\n",
      "验证集标签: (129,)\n",
      "测试集特征: (129, 163)\n",
      "测试集标签: (129,)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_MF.iloc[:].values\n",
    "X_val = df_val.iloc[:].values\n",
    "X_test = df_test.iloc[:].values\n",
    "\n",
    "df_MF = df_MF [ fileds_to_use ]\n",
    "df_val = df_val [ fileds_to_use ]\n",
    "df = df_test [ fileds_to_use ]\n",
    "\n",
    "X_train = df_MF.iloc[:].values\n",
    "X_val = df_val.iloc[:].values\n",
    "X_test = df.iloc[:].values\n",
    "\n",
    "y_train = pd.read_csv('train_molecule_dataset.csv')\n",
    "y_val = pd.read_csv('val_molecule_dataset.csv')\n",
    "y_test = pd.read_csv('test_molecule_dataset.csv')\n",
    "\n",
    "y_train = y_train['log_k'].values\n",
    "y_val = y_val['log_k'].values\n",
    "y_test = y_test['log_k'].values\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_val = y_val.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "print('训练集特征:', X_train.shape)\n",
    "print('训练集标签:', y_train.shape)\n",
    "print('验证集特征:', X_val.shape)\n",
    "print('验证集标签:', y_val.shape)\n",
    "print('测试集特征:', X_test.shape)\n",
    "print('测试集标签:', y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "#df_MF.to_csv('E:/GNN_new/新建文件夹/1291/straidified/gin_v2_e100_Adam_1e-03_seed1_2024-04-01-19-40/split_dataset/train_ECFP_163.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd4ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_train_RMSE=0.34781532692658845\n",
      "_val_RMSE=0.4259933150625517\n",
      "_test_RMSE=0.40221685887695885\n",
      "_train=0.6378642275496931\n",
      "_val=0.43821994142549814\n",
      "_test=0.4931161145534605\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = RandomForestRegressor(random_state=166, n_estimators= 400, min_samples_split=8, min_samples_leaf=1, max_features=1, max_depth=61)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf.predict(X_train)\n",
    "ResidualSquare = (y_pred1 - y_train)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_train_RMSE={RMSE}')\n",
    "\n",
    "y_pred2 = clf.predict(X_val)\n",
    "ResidualSquare = (y_pred2 - y_val)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_val_RMSE={RMSE}')\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "ResidualSquare = (y_pred - y_test)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_test_RMSE={RMSE}')\n",
    "\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_val = clf.score(X_val, y_val)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "print(f'_train={score_train}')\n",
    "print(f'_val={score_val}')\n",
    "print(f'_test={score_test}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8342797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'true':y_test, 'pred':y_pred}\n",
    "df = pd.DataFrame(a)\n",
    "df.to_csv('ECFP_test.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a6c9560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_train_RMSE=0.41921182143246843\n",
      "_val_RMSE=0.45225103908295594\n",
      "_test_RMSE=0.41392311686727545\n",
      "_train=0.4739330266615398\n",
      "_val=0.3668306293312483\n",
      "_test=0.46318170567681827\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = XGBRegressor(n_estimators=150, max_depth=8, learning_rate=0.34, gamma= 1.9, alpha=0.1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf.predict(X_train)\n",
    "ResidualSquare = (y_pred1 - y_train)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_train_RMSE={RMSE}')\n",
    "\n",
    "y_pred2 = clf.predict(X_val)\n",
    "ResidualSquare = (y_pred2 - y_val)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_val_RMSE={RMSE}')\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "ResidualSquare = (y_pred - y_test)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_test_RMSE={RMSE}')\n",
    "\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_val = clf.score(X_val, y_val)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "print(f'_train={score_train}')\n",
    "print(f'_val={score_val}')\n",
    "print(f'_test={score_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8465230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_train_RMSE=0.19640409759499028\n",
      "_val_RMSE=0.3678745915499091\n",
      "_test_RMSE=0.36342482651601815\n",
      "_train=0.8845284264026001\n",
      "_val=0.5810517921427125\n",
      "_test=0.5861746146818685\n"
     ]
    }
   ],
   "source": [
    "clf = SVR(gamma=0.23, epsilon=0.01, C=1.22, kernel = 'rbf')\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf.predict(X_train)\n",
    "ResidualSquare = (y_pred1 - y_train)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_train_RMSE={RMSE}')\n",
    "\n",
    "y_pred2 = clf.predict(X_val)\n",
    "ResidualSquare = (y_pred2 - y_val)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_val_RMSE={RMSE}')\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "ResidualSquare = (y_pred - y_test)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_test_RMSE={RMSE}')\n",
    "\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_val = clf.score(X_val, y_val)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "print(f'_train={score_train}')\n",
    "print(f'_val={score_val}')\n",
    "print(f'_test={score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f3d90e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_train_RMSE=0.43807479105723307\n",
      "_val_RMSE=0.4396395002893095\n",
      "_test_RMSE=0.40674461305914755\n",
      "_train=0.4255258110300173\n",
      "_val=0.4016515611269055\n",
      "_test=0.48163990094992415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (180) reached and the optimization hasn't converged yet.\n"
     ]
    }
   ],
   "source": [
    "clf = MLPRegressor(solver='adam',activation='relu',random_state=300, max_iter= 180, hidden_layer_sizes=(200, 200), alpha= 8.75 )\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf.predict(X_train)\n",
    "ResidualSquare = (y_pred1 - y_train)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_train_RMSE={RMSE}')\n",
    "\n",
    "y_pred2 = clf.predict(X_val)\n",
    "ResidualSquare = (y_pred2 - y_val)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_val_RMSE={RMSE}')\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "ResidualSquare = (y_pred - y_test)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_test_RMSE={RMSE}')\n",
    "\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_val = clf.score(X_val, y_val)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "print(f'_train={score_train}')\n",
    "print(f'_val={score_val}')\n",
    "print(f'_test={score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa16d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MF = pd.read_csv('1-MACCSmolecular_fingerprints.csv')\n",
    "df_val = pd.read_csv('2-MACCSmolecular_fingerprints.csv')\n",
    "df_test = pd.read_csv('3-MACCSmolecular_fingerprints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f737e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集特征: (1033, 167)\n",
      "训练集标签: (1033,)\n",
      "验证集特征: (129, 167)\n",
      "验证集标签: (129,)\n",
      "测试集特征: (129, 167)\n",
      "测试集标签: (129,)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_MF.iloc[:].values\n",
    "X_val = df_val.iloc[:].values\n",
    "X_test = df_test.iloc[:].values\n",
    "\n",
    "\n",
    "print('训练集特征:', X_train.shape)\n",
    "print('训练集标签:', y_train.shape)\n",
    "print('验证集特征:', X_val.shape)\n",
    "print('验证集标签:', y_val.shape)\n",
    "print('测试集特征:', X_test.shape)\n",
    "print('测试集标签:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "811248f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_train_RMSE=0.3110401693263717\n",
      "_val_RMSE=0.3782601219330774\n",
      "_test_RMSE=0.31584268895301687\n",
      "_train=0.7103944002413289\n",
      "_val=0.55706309411598\n",
      "_test=0.6874427325957001\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(random_state=100, n_estimators= 600, min_samples_split=8, min_samples_leaf=2, max_features=111, max_depth=16)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf.predict(X_train)\n",
    "ResidualSquare = (y_pred1 - y_train)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_train_RMSE={RMSE}')\n",
    "\n",
    "y_pred2 = clf.predict(X_val)\n",
    "ResidualSquare = (y_pred2 - y_val)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_val_RMSE={RMSE}')\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "ResidualSquare = (y_pred - y_test)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_test_RMSE={RMSE}')\n",
    "\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_val = clf.score(X_val, y_val)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "print(f'_train={score_train}')\n",
    "print(f'_val={score_val}')\n",
    "print(f'_test={score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f767de3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_train_RMSE=0.3758280128568985\n",
      "_val_RMSE=0.40111585534861466\n",
      "_test_RMSE=0.34938695051860835\n",
      "_train=0.5771831453962148\n",
      "_val=0.5019185020414721\n",
      "_test=0.6175265397697035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = XGBRegressor(n_estimators=150, max_depth=7, learning_rate=0.55, gamma= 4.0, alpha=0.1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf.predict(X_train)\n",
    "ResidualSquare = (y_pred1 - y_train)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_train_RMSE={RMSE}')\n",
    "\n",
    "y_pred2 = clf.predict(X_val)\n",
    "ResidualSquare = (y_pred2 - y_val)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_val_RMSE={RMSE}')\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "ResidualSquare = (y_pred - y_test)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_test_RMSE={RMSE}')\n",
    "\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_val = clf.score(X_val, y_val)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "print(f'_train={score_train}')\n",
    "print(f'_val={score_val}')\n",
    "print(f'_test={score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37351f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_train_RMSE=0.33033781898922027\n",
      "_val_RMSE=0.3763193688813958\n",
      "_test_RMSE=0.3359869902067554\n",
      "_train=0.6733440374719306\n",
      "_val=0.5615966192304371\n",
      "_test=0.6463017857128976\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = SVR(gamma=0.01, epsilon=0.14, C=2.8, kernel = 'rbf')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf.predict(X_train)\n",
    "ResidualSquare = (y_pred1 - y_train)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_train_RMSE={RMSE}')\n",
    "\n",
    "y_pred2 = clf.predict(X_val)\n",
    "ResidualSquare = (y_pred2 - y_val)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_val_RMSE={RMSE}')\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "ResidualSquare = (y_pred - y_test)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_test_RMSE={RMSE}')\n",
    "\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_val = clf.score(X_val, y_val)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "print(f'_train={score_train}')\n",
    "print(f'_val={score_val}')\n",
    "print(f'_test={score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7979424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'true':y_train, 'pred':y_pred1}\n",
    "df = pd.DataFrame(a)\n",
    "df.to_csv('MACCS_train.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b0576229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_train_RMSE=0.193175456895385\n",
      "_val_RMSE=0.4273147223246749\n",
      "_test_RMSE=0.373349355488417\n",
      "_train=0.8882936421762012\n",
      "_val=0.4347293157671066\n",
      "_test=0.5632642370704175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (140) reached and the optimization hasn't converged yet.\n"
     ]
    }
   ],
   "source": [
    "clf = MLPRegressor(solver='adam',activation='relu',random_state=233, max_iter= 140, hidden_layer_sizes=(167, 167), alpha= 0.85 )\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf.predict(X_train)\n",
    "ResidualSquare = (y_pred1 - y_train)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_train_RMSE={RMSE}')\n",
    "\n",
    "y_pred2 = clf.predict(X_val)\n",
    "ResidualSquare = (y_pred2 - y_val)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_val_RMSE={RMSE}')\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "ResidualSquare = (y_pred - y_test)**2\n",
    "MSE = np.mean(ResidualSquare)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(f'_test_RMSE={RMSE}')\n",
    "\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_val = clf.score(X_val, y_val)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "print(f'_train={score_train}')\n",
    "print(f'_val={score_val}')\n",
    "print(f'_test={score_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
